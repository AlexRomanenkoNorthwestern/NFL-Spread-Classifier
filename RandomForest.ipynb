<<<<<<< HEAD
{"cells":[{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","import numpy as np\n","import copy\n","import random\n","\n","# Read the CSV file into a DataFrame\n","data = pd.read_csv('sample_data/Final_Data_NFL.csv')\n","\n","# Creating a new DataFrame with all columns except 'column2' and 'column4'\n","columns_to_exclude = ['Day', 'Date', 'Time', 'Favorite', 'FavoriteTeamYear', 'UnderdogTeamYear',\n","                      'Score', 'Underdog', 'OverUnder', 'Season_Year', 'Favorite_Covered']\n","X = data.drop(columns=columns_to_exclude)\n","Y = data[\"Favorite_Covered\"]\n","\n","# Convert time of posession columns to numbers\n","for col_name in ['Favoriteaverage-time-of-possession-net-of-ot', 'Favoriteopponent-average-time-of-possession-net-of-ot', 'Underdogaverage-time-of-possession-net-of-ot', 'Underdogopponent-average-time-of-possession-net-of-ot']:\n","  col_data = X[col_name]\n","  new_col_data = []\n","  for row in col_data:\n","    split_data = row.split(':')\n","    col_data = 60*int(split_data[0]) + int(split_data[1])\n","    new_col_data.append(col_data)\n","  X[col_name] = new_col_data\n","\n","# Convert % to float\n","for col_name in [\n","    \"Favoritered-zone-scoring-pct\", \"Favoritethird-down-conversion-pct\", \"Favoritefield-goal-conversion-pct\",\n","    \"Favoriteopponent-red-zone-scoring-pct\", \"Favoriteopponent-third-down-conversion-pct\", \"Favoriteopponent-completion-pct\",\n","    \"Favoriteopponent-field-goal-conversion-pct\", \"Underdogred-zone-scoring-pct\", \"Underdogthird-down-conversion-pct\",\n","    \"Underdogfield-goal-conversion-pct\", \"Underdogopponent-red-zone-scoring-pct\", \"Underdogopponent-third-down-conversion-pct\",\n","    \"Underdogopponent-completion-pct\", \"Underdogopponent-field-goal-conversion-pct\"\n","]:\n","  col_data = X[col_name]\n","  new_col_data = []\n","  for row in col_data:\n","    col_data = row[0:-1]\n","    new_col_data.append(col_data)\n","  X[col_name] = new_col_data\n","\n","# If there is not a reported spread, get rid of the row of data\n","indices = []\n","for i, row in enumerate(X['Spread']):\n","  if str(row) == 'nan':\n","    indices.append(i)\n","X = X.drop(indices)\n","Y = Y.drop(indices)\n","\n","\n","# If there is a push and both sides of bet get their money back -set the label to T\n","new_Y = []\n","for row in Y:\n","  if row == 'T' or row == 'F':\n","    val = row\n","  else:\n","    val = 'T'\n","  new_Y.append(val)\n","Y = pd.Series(new_Y)\n","\n","# Splitting the data into training and testing sets(70%, 15%, 15%) - 5 times\n","# We will choose the most classified label provided by the 5 random forests when making predictions\n","X_temp1, X_test, y_temp1, y_test= train_test_split(X, Y, test_size=0.15, random_state=1)\n","X_train1, X_valid1, y_train1, y_valid1 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=1)\n","X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=2)\n","X_train3, X_valid3, y_train3, y_valid3 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=3)\n","X_train4, X_valid4, y_train4, y_valid4 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=4)\n","X_train5, X_valid5, y_train5, y_valid5 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=5)\n","X_train6, X_valid6, y_train6, y_valid6 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=6)\n","X_train7, X_valid7, y_train7, y_valid7 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=7)\n","X_train8, X_valid8, y_train8, y_valid8 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=8)\n","X_train9, X_valid9, y_train9, y_valid9 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=9)\n","X_train10, X_valid10, y_train10, y_valid10 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=10)\n","X_train11, X_valid11, y_train11, y_valid11 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=11)\n","\n","best_valid_accuracy = 0\n","best_classifier1 = None\n","best_classifier2 = None\n","best_classifier3 = None\n","best_classifier4 = None\n","best_classifier5 = None\n","best_classifier6 = None\n","best_classifier7 = None\n","best_classifier8 = None\n","best_classifier9 = None\n","best_classifier10 = None\n","best_classifier11 = None\n","best_criterion = None\n","best_min_samples_split = None\n","best_max_features = None\n","# Creating a Random Forest classifier - based on 100 decision trees\n","criterion_iter = -1\n","for criterion in [\"gini\", \"entropy\"]:\n","  criterion_iter += 1\n","  for min_samples_split in range(2, 100, 5):\n","    print(\"Progress =\", round(min_samples_split/200 * 100 + (criterion_iter*50),2), \"%\")\n","    for max_features in [10, 20, 30, 40, 50, \"sqrt\"]:\n","      rf_classifier1 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=1)\n","      rf_classifier2 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=2)\n","      rf_classifier3 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=3)\n","      rf_classifier4 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=4)\n","      rf_classifier5 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=5)\n","      rf_classifier6 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=6)\n","      rf_classifier7 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=7)\n","      rf_classifier8 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=8)\n","      rf_classifier9 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=9)\n","      rf_classifier10 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=10)\n","      rf_classifier11 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=11)\n","\n","      # Training the classifier\n","      rf_classifier1.fit(X_train1, y_train1)\n","      rf_classifier2.fit(X_train2, y_train2)\n","      rf_classifier3.fit(X_train3, y_train3)\n","      rf_classifier4.fit(X_train4, y_train4)\n","      rf_classifier5.fit(X_train5, y_train5)\n","      rf_classifier6.fit(X_train6, y_train6)\n","      rf_classifier7.fit(X_train7, y_train7)\n","      rf_classifier8.fit(X_train8, y_train8)\n","      rf_classifier9.fit(X_train9, y_train9)\n","      rf_classifier10.fit(X_train10, y_train10)\n","      rf_classifier11.fit(X_train11, y_train11)\n","\n","      # Predicting on the valid set\n","      predictions_valid1 = rf_classifier1.predict(X_valid1)\n","      predictions_valid2 = rf_classifier2.predict(X_valid2)\n","      predictions_valid3 = rf_classifier3.predict(X_valid3)\n","      predictions_valid4 = rf_classifier4.predict(X_valid4)\n","      predictions_valid5 = rf_classifier5.predict(X_valid5)\n","      predictions_valid6 = rf_classifier6.predict(X_valid6)\n","      predictions_valid7 = rf_classifier7.predict(X_valid7)\n","      predictions_valid8 = rf_classifier8.predict(X_valid8)\n","      predictions_valid9 = rf_classifier9.predict(X_valid9)\n","      predictions_valid10 = rf_classifier10.predict(X_valid10)\n","      predictions_valid11 = rf_classifier11.predict(X_valid11)\n","\n","      # Calculating accuracy - valid\n","      valid_accuracy1 = accuracy_score(y_valid1, predictions_valid1)\n","      valid_accuracy2 = accuracy_score(y_valid2, predictions_valid2)\n","      valid_accuracy3 = accuracy_score(y_valid3, predictions_valid3)\n","      valid_accuracy4 = accuracy_score(y_valid4, predictions_valid4)\n","      valid_accuracy5 = accuracy_score(y_valid5, predictions_valid5)\n","      valid_accuracy6 = accuracy_score(y_valid6, predictions_valid6)\n","      valid_accuracy7 = accuracy_score(y_valid7, predictions_valid7)\n","      valid_accuracy8 = accuracy_score(y_valid8, predictions_valid8)\n","      valid_accuracy9 = accuracy_score(y_valid9, predictions_valid9)\n","      valid_accuracy10 = accuracy_score(y_valid10, predictions_valid10)\n","      valid_accuracy11 = accuracy_score(y_valid11, predictions_valid11)\n","      valid_accuracy = (valid_accuracy1 + valid_accuracy2 + valid_accuracy3 + valid_accuracy4 + valid_accuracy5 + valid_accuracy6 + valid_accuracy7 + valid_accuracy8 + valid_accuracy9 + valid_accuracy10 + valid_accuracy11)/11\n","\n","      if valid_accuracy > best_valid_accuracy:\n","        best_valid_accuracy = valid_accuracy\n","        best_classifier1 = copy.deepcopy(rf_classifier1)\n","        best_classifier2 = copy.deepcopy(rf_classifier2)\n","        best_classifier3 = copy.deepcopy(rf_classifier3)\n","        best_classifier4 = copy.deepcopy(rf_classifier4)\n","        best_classifier5 = copy.deepcopy(rf_classifier5)\n","        best_classifier6 = copy.deepcopy(rf_classifier6)\n","        best_classifier7 = copy.deepcopy(rf_classifier7)\n","        best_classifier8 = copy.deepcopy(rf_classifier8)\n","        best_classifier9 = copy.deepcopy(rf_classifier9)\n","        best_classifier10 = copy.deepcopy(rf_classifier10)\n","        best_classifier11 = copy.deepcopy(rf_classifier11)\n","\n","        best_criterion = criterion\n","        best_min_samples_split = min_samples_split\n","        best_max_features = max_features\n","\n","# Predicting on the train set\n","predictions_train1 = rf_classifier1.predict(X_train1)\n","predictions_train2 = rf_classifier2.predict(X_train2)\n","predictions_train3 = rf_classifier3.predict(X_train3)\n","predictions_train4 = rf_classifier4.predict(X_train4)\n","predictions_train5 = rf_classifier5.predict(X_train5)\n","predictions_train6 = rf_classifier6.predict(X_train6)\n","predictions_train7 = rf_classifier7.predict(X_train7)\n","predictions_train8 = rf_classifier8.predict(X_train8)\n","predictions_train9 = rf_classifier9.predict(X_train9)\n","predictions_train10 = rf_classifier10.predict(X_train10)\n","predictions_train11 = rf_classifier11.predict(X_train11)\n","\n","train_accuracy1 = accuracy_score(y_train1, predictions_train1)\n","train_accuracy2 = accuracy_score(y_train2, predictions_train2)\n","train_accuracy3 = accuracy_score(y_train3, predictions_train3)\n","train_accuracy4 = accuracy_score(y_train4, predictions_train4)\n","train_accuracy5 = accuracy_score(y_train5, predictions_train5)\n","train_accuracy6 = accuracy_score(y_train6, predictions_train6)\n","train_accuracy7 = accuracy_score(y_train7, predictions_train7)\n","train_accuracy8 = accuracy_score(y_train8, predictions_train8)\n","train_accuracy9 = accuracy_score(y_train9, predictions_train9)\n","train_accuracy10 = accuracy_score(y_train10, predictions_train10)\n","train_accuracy11 = accuracy_score(y_train11, predictions_train11)\n","train_accuracy = (train_accuracy1 + train_accuracy2 + train_accuracy3 + train_accuracy4 + train_accuracy5 + train_accuracy6 + train_accuracy7 + train_accuracy8 + train_accuracy9 + train_accuracy10 + train_accuracy11)/11\n","print(f\"Avg Train Accuracy: {train_accuracy}\")\n","\n","# Predicting on the valid set\n","predictions_valid1 = rf_classifier1.predict(X_valid1)\n","predictions_valid2 = rf_classifier2.predict(X_valid2)\n","predictions_valid3 = rf_classifier3.predict(X_valid3)\n","predictions_valid4 = rf_classifier4.predict(X_valid4)\n","predictions_valid5 = rf_classifier5.predict(X_valid5)\n","predictions_valid6 = rf_classifier6.predict(X_valid6)\n","predictions_valid7 = rf_classifier7.predict(X_valid7)\n","predictions_valid8 = rf_classifier8.predict(X_valid8)\n","predictions_valid9 = rf_classifier9.predict(X_valid9)\n","predictions_valid10 = rf_classifier10.predict(X_valid10)\n","predictions_valid11 = rf_classifier11.predict(X_valid11)\n","\n","valid_accuracy1 = accuracy_score(y_valid1, predictions_valid1)\n","valid_accuracy2 = accuracy_score(y_valid2, predictions_valid2)\n","valid_accuracy3 = accuracy_score(y_valid3, predictions_valid3)\n","valid_accuracy4 = accuracy_score(y_valid4, predictions_valid4)\n","valid_accuracy5 = accuracy_score(y_valid5, predictions_valid5)\n","valid_accuracy6 = accuracy_score(y_valid6, predictions_valid6)\n","valid_accuracy7 = accuracy_score(y_valid7, predictions_valid7)\n","valid_accuracy8 = accuracy_score(y_valid8, predictions_valid8)\n","valid_accuracy9 = accuracy_score(y_valid9, predictions_valid9)\n","valid_accuracy10 = accuracy_score(y_valid10, predictions_valid10)\n","valid_accuracy11 = accuracy_score(y_valid11, predictions_valid11)\n","valid_accuracy = (valid_accuracy1 + valid_accuracy2 + valid_accuracy3 + valid_accuracy4 + valid_accuracy5 + valid_accuracy6 + valid_accuracy7 + valid_accuracy8 + valid_accuracy9 + valid_accuracy10 + valid_accuracy11)/11\n","print(f\"Avg Valid Accuracy: {valid_accuracy}\")\n","\n","# Predicting on the test set\n","predictions_test1 = rf_classifier1.predict(X_test)\n","predictions_test2 = rf_classifier2.predict(X_test)\n","predictions_test3 = rf_classifier3.predict(X_test)\n","predictions_test4 = rf_classifier4.predict(X_test)\n","predictions_test5 = rf_classifier5.predict(X_test)\n","predictions_test6 = rf_classifier6.predict(X_test)\n","predictions_test7 = rf_classifier7.predict(X_test)\n","predictions_test8 = rf_classifier8.predict(X_test)\n","predictions_test9 = rf_classifier9.predict(X_test)\n","predictions_test10 = rf_classifier10.predict(X_test)\n","predictions_test11 = rf_classifier11.predict(X_test)\n","\n","test_accuracy1 = accuracy_score(y_test, predictions_test1)\n","test_accuracy2 = accuracy_score(y_test, predictions_test2)\n","test_accuracy3 = accuracy_score(y_test, predictions_test3)\n","test_accuracy4 = accuracy_score(y_test, predictions_test4)\n","test_accuracy5 = accuracy_score(y_test, predictions_test5)\n","test_accuracy6 = accuracy_score(y_test, predictions_test6)\n","test_accuracy7 = accuracy_score(y_test, predictions_test7)\n","test_accuracy8 = accuracy_score(y_test, predictions_test8)\n","test_accuracy9 = accuracy_score(y_test, predictions_test9)\n","test_accuracy10 = accuracy_score(y_test, predictions_test10)\n","test_accuracy11 = accuracy_score(y_test, predictions_test11)\n","test_accuracy = (test_accuracy1 + test_accuracy2 + test_accuracy3 + test_accuracy4 + test_accuracy5 + test_accuracy6 + test_accuracy7 + test_accuracy8 + test_accuracy9 + test_accuracy10 + test_accuracy11)/11\n","print(f\"Avg Test Accuracy: {test_accuracy}\")\n","\n","pooled_predictions = []\n","for i in range(len(predictions_test1)):\n","  predicted_true = 0\n","  predicted_false = 0\n","  for prediction_list in [predictions_test1, predictions_test2, predictions_test3, predictions_test4, predictions_test5, predictions_test6, predictions_test7, predictions_test8, predictions_test9, predictions_test10, predictions_test11]:\n","    if prediction_list[i] == 'T':\n","       predicted_true += 1\n","    else:\n","      predicted_false += 1\n","  if predicted_true > predicted_false:\n","    pooled_predictions.append('T')\n","  else:\n","    pooled_predictions.append('F')\n","\n","pooled_test_accuracy = accuracy_score(y_test, pooled_predictions)\n","print(f\"Test Accuracy With Pooling: {pooled_test_accuracy}\")\n","\n","print(\"Criterion:\", best_criterion)\n","print(\"Min Samples To Split:\", best_min_samples_split)\n","print(\"Max Features:\", best_max_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_xpI_8wV7QEB","executionInfo":{"status":"ok","timestamp":1701071262536,"user_tz":360,"elapsed":1429943,"user":{"displayName":"Alexander Romanenko","userId":"05913195296226834875"}},"outputId":"ced55502-f339-4501-af55-a46b71be528d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Progress = 1.0 %\n","Progress = 3.5 %\n","Progress = 6.0 %\n","Progress = 8.5 %\n","Progress = 11.0 %\n","Progress = 13.5 %\n","Progress = 16.0 %\n","Progress = 18.5 %\n","Progress = 21.0 %\n","Progress = 23.5 %\n","Progress = 26.0 %\n","Progress = 28.5 %\n","Progress = 31.0 %\n","Progress = 33.5 %\n","Progress = 36.0 %\n","Progress = 38.5 %\n","Progress = 41.0 %\n","Progress = 43.5 %\n","Progress = 46.0 %\n","Progress = 48.5 %\n","Progress = 51.0 %\n","Progress = 53.5 %\n","Progress = 56.0 %\n","Progress = 58.5 %\n","Progress = 61.0 %\n","Progress = 63.5 %\n","Progress = 66.0 %\n","Progress = 68.5 %\n","Progress = 71.0 %\n","Progress = 73.5 %\n","Progress = 76.0 %\n","Progress = 78.5 %\n","Progress = 81.0 %\n","Progress = 83.5 %\n","Progress = 86.0 %\n","Progress = 88.5 %\n","Progress = 91.0 %\n","Progress = 93.5 %\n","Progress = 96.0 %\n","Progress = 98.5 %\n","Avg Train Accuracy: 0.7844230268299036\n","Avg Valid Accuracy: 0.49670972459176216\n","Avg Test Accuracy: 0.5430238210986874\n","Test Accuracy With Pooling: 0.5614973262032086\n","Criterion: gini\n","Min Samples To Split: 77\n","Max Features: sqrt\n"]}]},{"cell_type":"code","source":["pooled_predictions = []\n","y_test_new = []\n","\n","for i in range(len(predictions_test1)):\n","  predicted_true = 0\n","  predicted_false = 0\n","  for prediction_list in [predictions_test1, predictions_test2, predictions_test3, predictions_test4, predictions_test5, predictions_test6, predictions_test7, predictions_test8, predictions_test9, predictions_test10, predictions_test11]:\n","    if prediction_list[i] == 'T':\n","       predicted_true += 1\n","    else:\n","      predicted_false += 1\n","  if predicted_true >= 10:\n","    pooled_predictions.append('T')\n","    y_test_new.append(y_test.iloc[i])\n","  elif predicted_false >= 10:\n","    pooled_predictions.append('F')\n","    y_test_new.append(y_test.iloc[i])\n","\n","pooled_test_accuracy = accuracy_score(y_test_new, pooled_predictions)\n","print(f\"Higher Confidence Test Accuracy: {pooled_test_accuracy}\")\n","print(\"% Predictions\", len(y_test_new)/len(y_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4tDk59XViiRA","executionInfo":{"status":"ok","timestamp":1701071677548,"user_tz":360,"elapsed":166,"user":{"displayName":"Alexander Romanenko","userId":"05913195296226834875"}},"outputId":"8b36ef64-c32e-4959-c9b8-c69822272c86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Higher Confidence Test Accuracy: 0.6031746031746031\n","% Predictions 0.33689839572192515\n"]}]},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","import numpy as np\n","import copy\n","import random\n","\n","# Read the CSV file into a DataFrame\n","data = pd.read_csv('sample_data/Final_Data_NFL.csv')\n","\n","# Creating a new DataFrame with all columns except 'column2' and 'column4'\n","columns_to_exclude = ['Day', 'Date', 'Time', 'Favorite', 'FavoriteTeamYear', 'UnderdogTeamYear',\n","                      'Score', 'Underdog', 'OverUnder', 'Season_Year', 'Favorite_Covered']\n","X = data.drop(columns=columns_to_exclude)\n","Y = data[\"Favorite_Covered\"]\n","\n","# Convert time of posession columns to numbers\n","for col_name in ['Favoriteaverage-time-of-possession-net-of-ot', 'Favoriteopponent-average-time-of-possession-net-of-ot', 'Underdogaverage-time-of-possession-net-of-ot', 'Underdogopponent-average-time-of-possession-net-of-ot']:\n","  col_data = X[col_name]\n","  new_col_data = []\n","  for row in col_data:\n","    split_data = row.split(':')\n","    col_data = 60*int(split_data[0]) + int(split_data[1])\n","    new_col_data.append(col_data)\n","  X[col_name] = new_col_data\n","\n","# Convert % to float\n","for col_name in [\n","    \"Favoritered-zone-scoring-pct\", \"Favoritethird-down-conversion-pct\", \"Favoritefield-goal-conversion-pct\",\n","    \"Favoriteopponent-red-zone-scoring-pct\", \"Favoriteopponent-third-down-conversion-pct\", \"Favoriteopponent-completion-pct\",\n","    \"Favoriteopponent-field-goal-conversion-pct\", \"Underdogred-zone-scoring-pct\", \"Underdogthird-down-conversion-pct\",\n","    \"Underdogfield-goal-conversion-pct\", \"Underdogopponent-red-zone-scoring-pct\", \"Underdogopponent-third-down-conversion-pct\",\n","    \"Underdogopponent-completion-pct\", \"Underdogopponent-field-goal-conversion-pct\"\n","]:\n","  col_data = X[col_name]\n","  new_col_data = []\n","  for row in col_data:\n","    col_data = row[0:-1]\n","    new_col_data.append(col_data)\n","  X[col_name] = new_col_data\n","\n","# If there is not a reported spread, get rid of the row of data\n","indices = []\n","for i, row in enumerate(X['Spread']):\n","  if str(row) == 'nan':\n","    indices.append(i)\n","X = X.drop(indices)\n","Y = Y.drop(indices)\n","\n","\n","# If there is a push and both sides of bet get their money back -set the label to T\n","new_Y = []\n","for row in Y:\n","  if row == 'T' or row == 'F':\n","    val = row\n","  else:\n","    val = 'T'\n","  new_Y.append(val)\n","Y = pd.Series(new_Y)\n","\n","# Splitting the data into training and testing sets(70%, 15%, 15%) - 5 times\n","# We will choose the most classified label provided by the 5 random forests when making predictions\n","avg_train_acc_list = []\n","avg_valid_acc_list = []\n","avg_test_acc_list = []\n","avg_test_acc_with_pooling_list = []\n","avg_pct_predictions = []\n","for state in range(5):\n","  X_temp1, X_test, y_temp1, y_test= train_test_split(X, Y, test_size=0.15, random_state=state)\n","  X_train1, X_valid1, y_train1, y_valid1 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=1)\n","  X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=2)\n","  X_train3, X_valid3, y_train3, y_valid3 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=3)\n","  X_train4, X_valid4, y_train4, y_valid4 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=4)\n","  X_train5, X_valid5, y_train5, y_valid5 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=5)\n","  X_train6, X_valid6, y_train6, y_valid6 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=6)\n","  X_train7, X_valid7, y_train7, y_valid7 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=7)\n","  X_train8, X_valid8, y_train8, y_valid8 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=8)\n","  X_train9, X_valid9, y_train9, y_valid9 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=9)\n","  X_train10, X_valid10, y_train10, y_valid10 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=10)\n","  X_train11, X_valid11, y_train11, y_valid11 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=11)\n","\n","  best_valid_accuracy = 0\n","  best_classifier1 = None\n","  best_classifier2 = None\n","  best_classifier3 = None\n","  best_classifier4 = None\n","  best_classifier5 = None\n","  best_classifier6 = None\n","  best_classifier7 = None\n","  best_classifier8 = None\n","  best_classifier9 = None\n","  best_classifier10 = None\n","  best_classifier11 = None\n","  best_criterion = None\n","  best_min_samples_split = None\n","  best_max_features = None\n","\n","  # Creating a Random Forest classifier - based on 100 decision trees -- DO THIS AT A HIGHER LEVEL to choose hyperparamater\n","  criterion_iter = -1\n","  for criterion in [\"gini\"]:\n","    criterion_iter += 1\n","    for min_samples_split in  range(2, 100, 5):\n","      print(\"Progress =\", round(min_samples_split/100 * 100 + (criterion_iter*50),2), \"%\")\n","      for max_features in [20, 30, 40, 50, \"sqrt\"]:\n","\n","        rf_classifier1 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=1)\n","        rf_classifier2 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=2)\n","        rf_classifier3 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=3)\n","        rf_classifier4 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=4)\n","        rf_classifier5 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=5)\n","        rf_classifier6 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=6)\n","        rf_classifier7 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=7)\n","        rf_classifier8 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=8)\n","        rf_classifier9 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=9)\n","        rf_classifier10 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=10)\n","        rf_classifier11 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=11)\n","\n","        # Training the classifier\n","        rf_classifier1.fit(X_train1, y_train1)\n","        rf_classifier2.fit(X_train2, y_train2)\n","        rf_classifier3.fit(X_train3, y_train3)\n","        rf_classifier4.fit(X_train4, y_train4)\n","        rf_classifier5.fit(X_train5, y_train5)\n","        rf_classifier6.fit(X_train6, y_train6)\n","        rf_classifier7.fit(X_train7, y_train7)\n","        rf_classifier8.fit(X_train8, y_train8)\n","        rf_classifier9.fit(X_train9, y_train9)\n","        rf_classifier10.fit(X_train10, y_train10)\n","        rf_classifier11.fit(X_train11, y_train11)\n","\n","        # Predicting on the valid set\n","        predictions_valid1 = rf_classifier1.predict(X_valid1)\n","        predictions_valid2 = rf_classifier2.predict(X_valid2)\n","        predictions_valid3 = rf_classifier3.predict(X_valid3)\n","        predictions_valid4 = rf_classifier4.predict(X_valid4)\n","        predictions_valid5 = rf_classifier5.predict(X_valid5)\n","        predictions_valid6 = rf_classifier6.predict(X_valid6)\n","        predictions_valid7 = rf_classifier7.predict(X_valid7)\n","        predictions_valid8 = rf_classifier8.predict(X_valid8)\n","        predictions_valid9 = rf_classifier9.predict(X_valid9)\n","        predictions_valid10 = rf_classifier10.predict(X_valid10)\n","        predictions_valid11 = rf_classifier11.predict(X_valid11)\n","\n","        # Calculating accuracy - valid\n","        valid_accuracy1 = accuracy_score(y_valid1, predictions_valid1)\n","        valid_accuracy2 = accuracy_score(y_valid2, predictions_valid2)\n","        valid_accuracy3 = accuracy_score(y_valid3, predictions_valid3)\n","        valid_accuracy4 = accuracy_score(y_valid4, predictions_valid4)\n","        valid_accuracy5 = accuracy_score(y_valid5, predictions_valid5)\n","        valid_accuracy6 = accuracy_score(y_valid6, predictions_valid6)\n","        valid_accuracy7 = accuracy_score(y_valid7, predictions_valid7)\n","        valid_accuracy8 = accuracy_score(y_valid8, predictions_valid8)\n","        valid_accuracy9 = accuracy_score(y_valid9, predictions_valid9)\n","        valid_accuracy10 = accuracy_score(y_valid10, predictions_valid10)\n","        valid_accuracy11 = accuracy_score(y_valid11, predictions_valid11)\n","        valid_accuracy = (valid_accuracy1 + valid_accuracy2 + valid_accuracy3 + valid_accuracy4 + valid_accuracy5 + valid_accuracy6 + valid_accuracy7 + valid_accuracy8 + valid_accuracy9 + valid_accuracy10 + valid_accuracy11)/11\n","\n","        if valid_accuracy > best_valid_accuracy:\n","          best_valid_accuracy = valid_accuracy\n","          best_classifier1 = copy.deepcopy(rf_classifier1)\n","          best_classifier2 = copy.deepcopy(rf_classifier2)\n","          best_classifier3 = copy.deepcopy(rf_classifier3)\n","          best_classifier4 = copy.deepcopy(rf_classifier4)\n","          best_classifier5 = copy.deepcopy(rf_classifier5)\n","          best_classifier6 = copy.deepcopy(rf_classifier6)\n","          best_classifier7 = copy.deepcopy(rf_classifier7)\n","          best_classifier8 = copy.deepcopy(rf_classifier8)\n","          best_classifier9 = copy.deepcopy(rf_classifier9)\n","          best_classifier10 = copy.deepcopy(rf_classifier10)\n","          best_classifier11 = copy.deepcopy(rf_classifier11)\n","\n","          best_criterion = criterion\n","          best_min_samples_split = min_samples_split\n","          best_max_features = max_features\n","\n","  # Predicting on the train set\n","  predictions_train1 = rf_classifier1.predict(X_train1)\n","  predictions_train2 = rf_classifier2.predict(X_train2)\n","  predictions_train3 = rf_classifier3.predict(X_train3)\n","  predictions_train4 = rf_classifier4.predict(X_train4)\n","  predictions_train5 = rf_classifier5.predict(X_train5)\n","  predictions_train6 = rf_classifier6.predict(X_train6)\n","  predictions_train7 = rf_classifier7.predict(X_train7)\n","  predictions_train8 = rf_classifier8.predict(X_train8)\n","  predictions_train9 = rf_classifier9.predict(X_train9)\n","  predictions_train10 = rf_classifier10.predict(X_train10)\n","  predictions_train11 = rf_classifier11.predict(X_train11)\n","\n","  train_accuracy1 = accuracy_score(y_train1, predictions_train1)\n","  train_accuracy2 = accuracy_score(y_train2, predictions_train2)\n","  train_accuracy3 = accuracy_score(y_train3, predictions_train3)\n","  train_accuracy4 = accuracy_score(y_train4, predictions_train4)\n","  train_accuracy5 = accuracy_score(y_train5, predictions_train5)\n","  train_accuracy6 = accuracy_score(y_train6, predictions_train6)\n","  train_accuracy7 = accuracy_score(y_train7, predictions_train7)\n","  train_accuracy8 = accuracy_score(y_train8, predictions_train8)\n","  train_accuracy9 = accuracy_score(y_train9, predictions_train9)\n","  train_accuracy10 = accuracy_score(y_train10, predictions_train10)\n","  train_accuracy11 = accuracy_score(y_train11, predictions_train11)\n","  train_accuracy = (train_accuracy1 + train_accuracy2 + train_accuracy3 + train_accuracy4 + train_accuracy5 + train_accuracy6 + train_accuracy7 + train_accuracy8 + train_accuracy9 + train_accuracy10 + train_accuracy11)/11\n","  avg_train_acc_list.append(train_accuracy)\n","\n","  # Predicting on the valid set\n","  predictions_valid1 = rf_classifier1.predict(X_valid1)\n","  predictions_valid2 = rf_classifier2.predict(X_valid2)\n","  predictions_valid3 = rf_classifier3.predict(X_valid3)\n","  predictions_valid4 = rf_classifier4.predict(X_valid4)\n","  predictions_valid5 = rf_classifier5.predict(X_valid5)\n","  predictions_valid6 = rf_classifier6.predict(X_valid6)\n","  predictions_valid7 = rf_classifier7.predict(X_valid7)\n","  predictions_valid8 = rf_classifier8.predict(X_valid8)\n","  predictions_valid9 = rf_classifier9.predict(X_valid9)\n","  predictions_valid10 = rf_classifier10.predict(X_valid10)\n","  predictions_valid11 = rf_classifier11.predict(X_valid11)\n","\n","  valid_accuracy1 = accuracy_score(y_valid1, predictions_valid1)\n","  valid_accuracy2 = accuracy_score(y_valid2, predictions_valid2)\n","  valid_accuracy3 = accuracy_score(y_valid3, predictions_valid3)\n","  valid_accuracy4 = accuracy_score(y_valid4, predictions_valid4)\n","  valid_accuracy5 = accuracy_score(y_valid5, predictions_valid5)\n","  valid_accuracy6 = accuracy_score(y_valid6, predictions_valid6)\n","  valid_accuracy7 = accuracy_score(y_valid7, predictions_valid7)\n","  valid_accuracy8 = accuracy_score(y_valid8, predictions_valid8)\n","  valid_accuracy9 = accuracy_score(y_valid9, predictions_valid9)\n","  valid_accuracy10 = accuracy_score(y_valid10, predictions_valid10)\n","  valid_accuracy11 = accuracy_score(y_valid11, predictions_valid11)\n","  valid_accuracy = (valid_accuracy1 + valid_accuracy2 + valid_accuracy3 + valid_accuracy4 + valid_accuracy5 + valid_accuracy6 + valid_accuracy7 + valid_accuracy8 + valid_accuracy9 + valid_accuracy10 + valid_accuracy11)/11\n","  avg_valid_acc_list.append(valid_accuracy)\n","\n","  # Predicting on the test set\n","  predictions_test1 = rf_classifier1.predict(X_test)\n","  predictions_test2 = rf_classifier2.predict(X_test)\n","  predictions_test3 = rf_classifier3.predict(X_test)\n","  predictions_test4 = rf_classifier4.predict(X_test)\n","  predictions_test5 = rf_classifier5.predict(X_test)\n","  predictions_test6 = rf_classifier6.predict(X_test)\n","  predictions_test7 = rf_classifier7.predict(X_test)\n","  predictions_test8 = rf_classifier8.predict(X_test)\n","  predictions_test9 = rf_classifier9.predict(X_test)\n","  predictions_test10 = rf_classifier10.predict(X_test)\n","  predictions_test11 = rf_classifier11.predict(X_test)\n","\n","  test_accuracy1 = accuracy_score(y_test, predictions_test1)\n","  test_accuracy2 = accuracy_score(y_test, predictions_test2)\n","  test_accuracy3 = accuracy_score(y_test, predictions_test3)\n","  test_accuracy4 = accuracy_score(y_test, predictions_test4)\n","  test_accuracy5 = accuracy_score(y_test, predictions_test5)\n","  test_accuracy6 = accuracy_score(y_test, predictions_test6)\n","  test_accuracy7 = accuracy_score(y_test, predictions_test7)\n","  test_accuracy8 = accuracy_score(y_test, predictions_test8)\n","  test_accuracy9 = accuracy_score(y_test, predictions_test9)\n","  test_accuracy10 = accuracy_score(y_test, predictions_test10)\n","  test_accuracy11 = accuracy_score(y_test, predictions_test11)\n","  test_accuracy = (test_accuracy1 + test_accuracy2 + test_accuracy3 + test_accuracy4 + test_accuracy5 + test_accuracy6 + test_accuracy7 + test_accuracy8 + test_accuracy9 + test_accuracy10 + test_accuracy11)/11\n","  avg_test_acc_list.append(test_accuracy)\n","\n","  pooled_predictions = []\n","  y_test_new = []\n","  for i in range(len(predictions_test1)):\n","    predicted_true = 0\n","    predicted_false = 0\n","    for prediction_list in [predictions_test1, predictions_test2, predictions_test3, predictions_test4, predictions_test5, predictions_test6, predictions_test7, predictions_test8, predictions_test9, predictions_test10, predictions_test11]:\n","      if prediction_list[i] == 'T':\n","        predicted_true += 1\n","      else:\n","        predicted_false += 1\n","    if predicted_true >= 6:\n","      pooled_predictions.append('T')\n","      y_test_new.append(y_test.iloc[i])\n","    elif predicted_false >= 6:\n","      pooled_predictions.append('F')\n","      y_test_new.append(y_test.iloc[i])\n","  pooled_test_accuracy6 = accuracy_score(y_test_new, pooled_predictions)\n","  avg_pct_predictions6 = (len(y_test_new)/len(y_test))\n","\n","  pooled_predictions = []\n","  y_test_new = []\n","  for i in range(len(predictions_test1)):\n","    predicted_true = 0\n","    predicted_false = 0\n","    for prediction_list in [predictions_test1, predictions_test2, predictions_test3, predictions_test4, predictions_test5, predictions_test6, predictions_test7, predictions_test8, predictions_test9, predictions_test10, predictions_test11]:\n","      if prediction_list[i] == 'T':\n","        predicted_true += 1\n","      else:\n","        predicted_false += 1\n","    if predicted_true >= 7:\n","      pooled_predictions.append('T')\n","      y_test_new.append(y_test.iloc[i])\n","    elif predicted_false >= 7:\n","      pooled_predictions.append('F')\n","      y_test_new.append(y_test.iloc[i])\n","  pooled_test_accuracy7 = accuracy_score(y_test_new, pooled_predictions)\n","  avg_pct_predictions7 = (len(y_test_new)/len(y_test))\n","\n","  pooled_predictions = []\n","  y_test_new = []\n","  for i in range(len(predictions_test1)):\n","    predicted_true = 0\n","    predicted_false = 0\n","    for prediction_list in [predictions_test1, predictions_test2, predictions_test3, predictions_test4, predictions_test5, predictions_test6, predictions_test7, predictions_test8, predictions_test9, predictions_test10, predictions_test11]:\n","      if prediction_list[i] == 'T':\n","        predicted_true += 1\n","      else:\n","        predicted_false += 1\n","    if predicted_true >= 8:\n","      pooled_predictions.append('T')\n","      y_test_new.append(y_test.iloc[i])\n","    elif predicted_false >= 8:\n","      pooled_predictions.append('F')\n","      y_test_new.append(y_test.iloc[i])\n","  pooled_test_accuracy8 = accuracy_score(y_test_new, pooled_predictions)\n","  avg_pct_predictions8 = (len(y_test_new)/len(y_test))\n","\n","  pooled_predictions = []\n","  y_test_new = []\n","  for i in range(len(predictions_test1)):\n","    predicted_true = 0\n","    predicted_false = 0\n","    for prediction_list in [predictions_test1, predictions_test2, predictions_test3, predictions_test4, predictions_test5, predictions_test6, predictions_test7, predictions_test8, predictions_test9, predictions_test10, predictions_test11]:\n","      if prediction_list[i] == 'T':\n","        predicted_true += 1\n","      else:\n","        predicted_false += 1\n","    if predicted_true >= 9:\n","      pooled_predictions.append('T')\n","      y_test_new.append(y_test.iloc[i])\n","    elif predicted_false >= 9:\n","      pooled_predictions.append('F')\n","      y_test_new.append(y_test.iloc[i])\n","  pooled_test_accuracy9 = accuracy_score(y_test_new, pooled_predictions)\n","  avg_pct_predictions9 = (len(y_test_new)/len(y_test))\n","\n","  pooled_predictions = []\n","  y_test_new = []\n","  for i in range(len(predictions_test1)):\n","    predicted_true = 0\n","    predicted_false = 0\n","    for prediction_list in [predictions_test1, predictions_test2, predictions_test3, predictions_test4, predictions_test5, predictions_test6, predictions_test7, predictions_test8, predictions_test9, predictions_test10, predictions_test11]:\n","      if prediction_list[i] == 'T':\n","        predicted_true += 1\n","      else:\n","        predicted_false += 1\n","    if predicted_true >= 10:\n","      pooled_predictions.append('T')\n","      y_test_new.append(y_test.iloc[i])\n","    elif predicted_false >= 10:\n","      pooled_predictions.append('F')\n","      y_test_new.append(y_test.iloc[i])\n","  pooled_test_accuracy10 = accuracy_score(y_test_new, pooled_predictions)\n","  avg_pct_predictions10 = (len(y_test_new)/len(y_test))\n","\n","  pooled_predictions = []\n","  y_test_new = []\n","  for i in range(len(predictions_test1)):\n","    predicted_true = 0\n","    predicted_false = 0\n","    for prediction_list in [predictions_test1, predictions_test2, predictions_test3, predictions_test4, predictions_test5, predictions_test6, predictions_test7, predictions_test8, predictions_test9, predictions_test10, predictions_test11]:\n","      if prediction_list[i] == 'T':\n","        predicted_true += 1\n","      else:\n","        predicted_false += 1\n","    if predicted_true >= 11:\n","      pooled_predictions.append('T')\n","      y_test_new.append(y_test.iloc[i])\n","    elif predicted_false >= 11:\n","      pooled_predictions.append('F')\n","      y_test_new.append(y_test.iloc[i])\n","  pooled_test_accuracy11 = accuracy_score(y_test_new, pooled_predictions)\n","  avg_pct_predictions11 = (len(y_test_new)/len(y_test))\n","\n","  avg_test_acc_with_pooling_list.append([pooled_test_accuracy6, pooled_test_accuracy7, pooled_test_accuracy8, pooled_test_accuracy9, pooled_test_accuracy10])\n","  avg_pct_predictions.append([avg_pct_predictions6, avg_pct_predictions7, avg_pct_predictions8, avg_pct_predictions9, avg_pct_predictions10, avg_pct_predictions11])\n","\n","print(avg_test_acc_with_pooling_list)\n","print(avg_pct_predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AhCSD9KwLvW","executionInfo":{"status":"ok","timestamp":1701576656324,"user_tz":360,"elapsed":2849419,"user":{"displayName":"Alexander Romanenko","userId":"05913195296226834875"}},"outputId":"985064df-5aae-4b04-a672-2c9e01d810a2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Progress = 2.0 %\n","Progress = 7.0 %\n","Progress = 12.0 %\n","Progress = 17.0 %\n","Progress = 22.0 %\n","Progress = 27.0 %\n","Progress = 32.0 %\n","Progress = 37.0 %\n","Progress = 42.0 %\n","Progress = 47.0 %\n","Progress = 52.0 %\n","Progress = 57.0 %\n","Progress = 62.0 %\n","Progress = 67.0 %\n","Progress = 72.0 %\n","Progress = 77.0 %\n","Progress = 82.0 %\n","Progress = 87.0 %\n","Progress = 92.0 %\n","Progress = 97.0 %\n","Progress = 2.0 %\n","Progress = 7.0 %\n","Progress = 12.0 %\n","Progress = 17.0 %\n","Progress = 22.0 %\n","Progress = 27.0 %\n","Progress = 32.0 %\n","Progress = 37.0 %\n","Progress = 42.0 %\n","Progress = 47.0 %\n","Progress = 52.0 %\n","Progress = 57.0 %\n","Progress = 62.0 %\n","Progress = 67.0 %\n","Progress = 72.0 %\n","Progress = 77.0 %\n","Progress = 82.0 %\n","Progress = 87.0 %\n","Progress = 92.0 %\n","Progress = 97.0 %\n","Progress = 2.0 %\n","Progress = 7.0 %\n","Progress = 12.0 %\n","Progress = 17.0 %\n","Progress = 22.0 %\n","Progress = 27.0 %\n","Progress = 32.0 %\n","Progress = 37.0 %\n","Progress = 42.0 %\n","Progress = 47.0 %\n","Progress = 52.0 %\n","Progress = 57.0 %\n","Progress = 62.0 %\n","Progress = 67.0 %\n","Progress = 72.0 %\n","Progress = 77.0 %\n","Progress = 82.0 %\n","Progress = 87.0 %\n","Progress = 92.0 %\n","Progress = 97.0 %\n","Progress = 2.0 %\n","Progress = 7.0 %\n","Progress = 12.0 %\n","Progress = 17.0 %\n","Progress = 22.0 %\n","Progress = 27.0 %\n","Progress = 32.0 %\n","Progress = 37.0 %\n","Progress = 42.0 %\n","Progress = 47.0 %\n","Progress = 52.0 %\n","Progress = 57.0 %\n","Progress = 62.0 %\n","Progress = 67.0 %\n","Progress = 72.0 %\n","Progress = 77.0 %\n","Progress = 82.0 %\n","Progress = 87.0 %\n","Progress = 92.0 %\n","Progress = 97.0 %\n","Progress = 2.0 %\n","Progress = 7.0 %\n","Progress = 12.0 %\n","Progress = 17.0 %\n","Progress = 22.0 %\n","Progress = 27.0 %\n","Progress = 32.0 %\n","Progress = 37.0 %\n","Progress = 42.0 %\n","Progress = 47.0 %\n","Progress = 52.0 %\n","Progress = 57.0 %\n","Progress = 62.0 %\n","Progress = 67.0 %\n","Progress = 72.0 %\n","Progress = 77.0 %\n","Progress = 82.0 %\n","Progress = 87.0 %\n","Progress = 92.0 %\n","Progress = 97.0 %\n","[[0.5481283422459893, 0.5508982035928144, 0.5692307692307692, 0.5846153846153846, 0.5905511811023622], [0.5561497326203209, 0.5541795665634675, 0.569672131147541, 0.6111111111111112, 0.5984251968503937], [0.5080213903743316, 0.5125, 0.4904214559386973, 0.5073170731707317, 0.5037037037037037], [0.5320855614973262, 0.5288753799392097, 0.5490909090909091, 0.5607476635514018, 0.5857142857142857], [0.5267379679144385, 0.5311475409836065, 0.5301204819277109, 0.5300546448087432, 0.5384615384615384]]\n","[[1.0, 0.893048128342246, 0.6951871657754011, 0.5213903743315508, 0.339572192513369, 0.18983957219251338], [1.0, 0.8636363636363636, 0.6524064171122995, 0.48128342245989303, 0.339572192513369, 0.16042780748663102], [1.0, 0.8556149732620321, 0.6978609625668449, 0.5481283422459893, 0.3609625668449198, 0.20588235294117646], [1.0, 0.8796791443850267, 0.7352941176470589, 0.5721925133689839, 0.37433155080213903, 0.1925133689839572], [1.0, 0.8155080213903744, 0.6657754010695187, 0.4893048128342246, 0.31283422459893045, 0.15508021390374332]]\n"]}]},{"cell_type":"code","source":["Aggr = 0\n","for arr in avg_pct_predictions:\n","  Aggr += arr[4]\n","print(Aggr/len(avg_pct_predictions))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7vtmcwEp7qs","executionInfo":{"status":"ok","timestamp":1701577313416,"user_tz":360,"elapsed":136,"user":{"displayName":"Alexander Romanenko","userId":"05913195296226834875"}},"outputId":"90b52362-b133-4557-d4c3-d0fd69b97aaf"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["0.3454545454545454\n"]}]},{"cell_type":"code","source":["import random\n","accuracies = []\n","for i in range(1000):\n","  random_list = [random.choice([\"T\", \"F\"]) for _ in range(len(y_test))]\n","  test_accuracy = accuracy_score(y_test, random_list)\n","  accuracies.append(test_accuracy)\n","print(f\"Accuracy: {sum(accuracies)/len(accuracies)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5noiRpTcV8_-","executionInfo":{"status":"ok","timestamp":1701064930900,"user_tz":360,"elapsed":1689,"user":{"displayName":"Alexander Romanenko","userId":"05913195296226834875"}},"outputId":"75139eb9-e768-44b0-a082-551a074c9653"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.5000775401069522\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOlBWjODMWN+3hjDuV/bUUm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
=======
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2149688,"status":"error","timestamp":1701055821642,"user":{"displayName":"Alexander Romanenko","userId":"05913195296226834875"},"user_tz":360},"id":"aeAodS3I0ssw","outputId":"e3f1b8b2-8a9e-40b5-a134-134d3246601f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Progress = 0.2 %\n","Progress = 0.7 %\n","Progress = 1.2 %\n","Progress = 1.7 %\n","Progress = 2.2 %\n","Progress = 2.7 %\n","Progress = 3.2 %\n","Progress = 3.7 %\n","Progress = 4.2 %\n","Progress = 4.7 %\n","Progress = 5.2 %\n","Progress = 5.7 %\n","Progress = 6.2 %\n","Progress = 6.7 %\n","Progress = 7.2 %\n","Progress = 7.7 %\n","Progress = 8.2 %\n","Progress = 8.7 %\n","Progress = 9.2 %\n","Progress = 9.7 %\n","Progress = 10.2 %\n","Progress = 10.7 %\n","Progress = 11.2 %\n","Progress = 11.7 %\n","Progress = 12.2 %\n","Progress = 12.7 %\n","Progress = 13.2 %\n","Progress = 13.7 %\n","Progress = 14.2 %\n","Progress = 14.7 %\n","Progress = 15.2 %\n","Progress = 15.7 %\n","Progress = 16.2 %\n","Progress = 16.7 %\n","Progress = 17.2 %\n","Progress = 17.7 %\n","Progress = 18.2 %\n","Progress = 18.7 %\n","Progress = 19.2 %\n","Progress = 19.7 %\n","Progress = 20.2 %\n","Progress = 20.7 %\n","Progress = 21.2 %\n","Progress = 21.7 %\n","Progress = 22.2 %\n","Progress = 22.7 %\n","Progress = 23.2 %\n","Progress = 23.7 %\n","Progress = 24.2 %\n","Progress = 24.7 %\n","Progress = 25.2 %\n","Progress = 25.7 %\n","Progress = 26.2 %\n","Progress = 26.7 %\n","Progress = 27.2 %\n","Progress = 27.7 %\n","Progress = 28.2 %\n","Progress = 28.7 %\n","Progress = 29.2 %\n","Progress = 29.7 %\n","Progress = 30.2 %\n","Progress = 30.7 %\n","Progress = 31.2 %\n","Progress = 31.7 %\n","Progress = 32.2 %\n","Progress = 32.7 %\n","Progress = 33.2 %\n","Progress = 33.7 %\n","Progress = 34.2 %\n","Progress = 34.7 %\n","Progress = 35.2 %\n","Progress = 35.7 %\n","Progress = 36.2 %\n","Progress = 36.7 %\n","Progress = 37.2 %\n","Progress = 37.7 %\n","Progress = 38.2 %\n","Progress = 38.7 %\n","Progress = 39.2 %\n","Progress = 39.7 %\n","Progress = 40.2 %\n","Progress = 40.7 %\n","Progress = 41.2 %\n","Progress = 41.7 %\n","Progress = 42.2 %\n","Progress = 42.7 %\n","Progress = 43.2 %\n","Progress = 43.7 %\n","Progress = 44.2 %\n","Progress = 44.7 %\n","Progress = 45.2 %\n","Progress = 45.7 %\n","Progress = 46.2 %\n","Progress = 46.7 %\n","Progress = 47.2 %\n","Progress = 47.7 %\n","Progress = 48.2 %\n","Progress = 48.7 %\n","Progress = 49.2 %\n","Progress = 49.7 %\n","Progress = 50.2 %\n","Progress = 50.7 %\n","Progress = 51.2 %\n","Progress = 51.7 %\n","Progress = 52.2 %\n","Progress = 52.7 %\n","Progress = 53.2 %\n","Progress = 53.7 %\n","Progress = 54.2 %\n","Progress = 54.7 %\n","Progress = 55.2 %\n","Progress = 55.7 %\n","Progress = 56.2 %\n","Progress = 56.7 %\n","Progress = 57.2 %\n","Progress = 57.7 %\n","Progress = 58.2 %\n","Progress = 58.7 %\n","Progress = 59.2 %\n","Progress = 59.7 %\n","Progress = 60.2 %\n","Progress = 60.7 %\n","Progress = 61.2 %\n","Progress = 61.7 %\n","Progress = 62.2 %\n","Progress = 62.7 %\n","Progress = 63.2 %\n","Progress = 63.7 %\n","Progress = 64.2 %\n","Progress = 64.7 %\n","Progress = 65.2 %\n","Progress = 65.7 %\n","Progress = 66.2 %\n","Progress = 66.7 %\n","Progress = 67.2 %\n","Progress = 67.7 %\n","Progress = 68.2 %\n","Progress = 68.7 %\n","Progress = 69.2 %\n","Progress = 69.7 %\n","Progress = 70.2 %\n","Progress = 70.7 %\n","Progress = 71.2 %\n","Progress = 71.7 %\n","Progress = 72.2 %\n","Progress = 72.7 %\n","Progress = 73.2 %\n","Progress = 73.7 %\n","Progress = 74.2 %\n","Progress = 74.7 %\n","Progress = 75.2 %\n","Progress = 75.7 %\n","Progress = 76.2 %\n","Progress = 76.7 %\n","Progress = 77.2 %\n","Progress = 77.7 %\n","Progress = 78.2 %\n","Progress = 78.7 %\n","Progress = 79.2 %\n","Progress = 79.7 %\n","Progress = 80.2 %\n","Progress = 80.7 %\n","Progress = 81.2 %\n","Progress = 81.7 %\n","Progress = 82.2 %\n","Progress = 82.7 %\n","Progress = 83.2 %\n","Progress = 83.7 %\n","Progress = 84.2 %\n","Progress = 84.7 %\n","Progress = 85.2 %\n","Progress = 85.7 %\n","Progress = 86.2 %\n","Progress = 86.7 %\n","Progress = 87.2 %\n","Progress = 87.7 %\n","Progress = 88.2 %\n","Progress = 88.7 %\n","Progress = 89.2 %\n","Progress = 89.7 %\n","Progress = 90.2 %\n","Progress = 90.7 %\n","Progress = 91.2 %\n","Progress = 91.7 %\n","Progress = 92.2 %\n","Progress = 92.7 %\n","Progress = 93.2 %\n","Progress = 93.7 %\n","Progress = 94.2 %\n","Progress = 94.7 %\n","Progress = 95.2 %\n","Progress = 95.7 %\n","Progress = 96.2 %\n","Progress = 96.7 %\n","Progress = 97.2 %\n","Progress = 97.7 %\n","Progress = 98.2 %\n","Progress = 98.7 %\n","Progress = 99.2 %\n","Progress = 99.7 %\n","Avg Train Accuracy: 0.620515759312321\n","Avg Valid Accuracy: 0.49758713136729227\n","Avg Test Accuracy: 0.509624234777996\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-99-3e8a36e78373>\u001b[0m in \u001b[0;36m<cell line: 172>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0mpooled_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m   \u001b[0mpredicted_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0mpredicted_false\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"]}],"source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","import numpy as np\n","import copy\n","import random\n","\n","# Read the CSV file into a DataFrame\n","data = pd.read_csv('sample_data/Final_Data_NFL.csv')\n","\n","# Creating a new DataFrame with all columns except 'column2' and 'column4'\n","columns_to_exclude = ['Day', 'Date', 'Time', 'Favorite', 'FavoriteTeamYear', 'UnderdogTeamYear',\n","                      'Score', 'Underdog', 'OverUnder', 'Season_Year', 'Favorite_Covered']\n","X = data.drop(columns=columns_to_exclude)\n","Y = data[\"Favorite_Covered\"]\n","\n","# Convert time of posession columns to numbers\n","for col_name in ['Favoriteaverage-time-of-possession-net-of-ot', 'Favoriteopponent-average-time-of-possession-net-of-ot', 'Underdogaverage-time-of-possession-net-of-ot', 'Underdogopponent-average-time-of-possession-net-of-ot']:\n","  col_data = X[col_name]\n","  new_col_data = []\n","  for row in col_data:\n","    split_data = row.split(':')\n","    col_data = 60*int(split_data[0]) + int(split_data[1])\n","    new_col_data.append(col_data)\n","  X[col_name] = new_col_data\n","\n","# Convert % to float\n","for col_name in [\n","    \"Favoritered-zone-scoring-pct\", \"Favoritethird-down-conversion-pct\", \"Favoritefield-goal-conversion-pct\",\n","    \"Favoriteopponent-red-zone-scoring-pct\", \"Favoriteopponent-third-down-conversion-pct\", \"Favoriteopponent-completion-pct\",\n","    \"Favoriteopponent-field-goal-conversion-pct\", \"Underdogred-zone-scoring-pct\", \"Underdogthird-down-conversion-pct\",\n","    \"Underdogfield-goal-conversion-pct\", \"Underdogopponent-red-zone-scoring-pct\", \"Underdogopponent-third-down-conversion-pct\",\n","    \"Underdogopponent-completion-pct\", \"Underdogopponent-field-goal-conversion-pct\"\n","]:\n","  col_data = X[col_name]\n","  new_col_data = []\n","  for row in col_data:\n","    col_data = row[0:-1]\n","    new_col_data.append(col_data)\n","  X[col_name] = new_col_data\n","\n","# If there is not a reported spread, get rid of the row of data\n","indices = []\n","for i, row in enumerate(X['Spread']):\n","  if str(row) == 'nan':\n","    indices.append(i)\n","X = X.drop(indices)\n","Y = Y.drop(indices)\n","\n","\n","# If there is a push and both sides of bet get their money back -set the label to P\n","new_Y = []\n","for row in Y:\n","  if row == 'T' or row == 'F':\n","    val = row\n","  else:\n","    val = 'T'\n","  new_Y.append(val)\n","Y = pd.Series(new_Y)\n","\n","# Splitting the data into training and testing sets(70%, 15%, 15%) - 5 times\n","# We will choose the most classified label provided by the 5 random forests when making predictions\n","X_temp1, X_test, y_temp1, y_test= train_test_split(X, Y, test_size=0.15, random_state=1)\n","X_train1, X_valid1, y_train1, y_valid1 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=1)\n","X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=2)\n","X_train3, X_valid3, y_train3, y_valid3 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=3)\n","X_train4, X_valid4, y_train4, y_valid4 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=4)\n","X_train5, X_valid5, y_train5, y_valid5 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=5)\n","\n","best_valid_accuracy = 0\n","best_classifier1 = None\n","best_classifier2 = None\n","best_classifier3 = None\n","best_classifier4 = None\n","best_classifier5 = None\n","best_criterion = None\n","best_min_samples_split = None\n","best_max_features = None\n","# Creating a Random Forest classifier - based on 100 decision trees\n","criterion_iter = -1\n","for criterion in [\"gini\", \"entropy\"]:\n","  criterion_iter += 1\n","  for min_samples_split in range(2, 500, 5):\n","    print(\"Progress =\", round(min_samples_split/1000 * 100 + (criterion_iter*50),2), \"%\")\n","    for max_features in [10, 20, 30, 40, 50, \"sqrt\"]:\n","      rf_classifier1 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=1)\n","      rf_classifier2 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=2)\n","      rf_classifier3 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=3)\n","      rf_classifier4 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=4)\n","      rf_classifier5 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=5)\n","\n","      # Training the classifier\n","      rf_classifier1.fit(X_train1, y_train1)\n","      rf_classifier2.fit(X_train2, y_train2)\n","      rf_classifier3.fit(X_train3, y_train3)\n","      rf_classifier4.fit(X_train4, y_train4)\n","      rf_classifier5.fit(X_train5, y_train5)\n","\n","      # Predicting on the valid set\n","      predictions_valid1 = rf_classifier1.predict(X_valid1)\n","      predictions_valid2 = rf_classifier2.predict(X_valid2)\n","      predictions_valid3 = rf_classifier3.predict(X_valid3)\n","      predictions_valid4 = rf_classifier4.predict(X_valid4)\n","      predictions_valid5 = rf_classifier5.predict(X_valid5)\n","\n","      # Calculating accuracy - valid\n","      valid_accuracy1 = accuracy_score(y_valid1, predictions_valid1)\n","      valid_accuracy2 = accuracy_score(y_valid2, predictions_valid2)\n","      valid_accuracy3 = accuracy_score(y_valid3, predictions_valid3)\n","      valid_accuracy4 = accuracy_score(y_valid4, predictions_valid4)\n","      valid_accuracy5 = accuracy_score(y_valid5, predictions_valid5)\n","      valid_accuracy = (valid_accuracy1 + valid_accuracy2 + valid_accuracy3 + valid_accuracy4 + valid_accuracy5)/5\n","\n","      if valid_accuracy > best_valid_accuracy:\n","        best_valid_accuracy = valid_accuracy\n","        best_classifier1 = copy.deepcopy(rf_classifier1)\n","        best_classifier2 = copy.deepcopy(rf_classifier2)\n","        best_classifier3 = copy.deepcopy(rf_classifier3)\n","        best_classifier4 = copy.deepcopy(rf_classifier4)\n","        best_classifier5 = copy.deepcopy(rf_classifier5)\n","        best_criterion = criterion\n","        best_min_samples_split = min_samples_split\n","        best_max_features = max_features\n","\n","# Predicting on the train set\n","predictions_train1 = rf_classifier1.predict(X_train1)\n","predictions_train2 = rf_classifier2.predict(X_train2)\n","predictions_train3 = rf_classifier3.predict(X_train3)\n","predictions_train4 = rf_classifier4.predict(X_train4)\n","predictions_train5 = rf_classifier5.predict(X_train5)\n","\n","train_accuracy1 = accuracy_score(y_train1, predictions_train1)\n","train_accuracy2 = accuracy_score(y_train2, predictions_train2)\n","train_accuracy3 = accuracy_score(y_train3, predictions_train3)\n","train_accuracy4 = accuracy_score(y_train4, predictions_train4)\n","train_accuracy5 = accuracy_score(y_train5, predictions_train5)\n","train_accuracy = (train_accuracy1 + train_accuracy2 + train_accuracy3 + train_accuracy4 + train_accuracy5)/5\n","print(f\"Avg Train Accuracy: {train_accuracy}\")\n","\n","# Predicting on the valid set\n","predictions_valid1 = rf_classifier1.predict(X_valid1)\n","predictions_valid2 = rf_classifier2.predict(X_valid2)\n","predictions_valid3 = rf_classifier3.predict(X_valid3)\n","predictions_valid4 = rf_classifier4.predict(X_valid4)\n","predictions_valid5 = rf_classifier5.predict(X_valid5)\n","\n","valid_accuracy1 = accuracy_score(y_valid1, predictions_valid1)\n","valid_accuracy2 = accuracy_score(y_valid2, predictions_valid2)\n","valid_accuracy3 = accuracy_score(y_valid3, predictions_valid3)\n","valid_accuracy4 = accuracy_score(y_valid4, predictions_valid4)\n","valid_accuracy5 = accuracy_score(y_valid5, predictions_valid5)\n","valid_accuracy = (valid_accuracy1 + valid_accuracy2 + valid_accuracy3 + valid_accuracy4 + valid_accuracy5)/5\n","print(f\"Avg Valid Accuracy: {valid_accuracy}\")\n","\n","# Predicting on the test set\n","predictions_test1 = rf_classifier1.predict(X_test)\n","predictions_test2 = rf_classifier2.predict(X_test)\n","predictions_test3 = rf_classifier3.predict(X_test)\n","predictions_test4 = rf_classifier4.predict(X_test)\n","predictions_test5 = rf_classifier5.predict(X_test)\n","\n","test_accuracy1 = accuracy_score(y_test, predictions_test1)\n","test_accuracy2 = accuracy_score(y_test, predictions_test2)\n","test_accuracy3 = accuracy_score(y_test, predictions_test3)\n","test_accuracy4 = accuracy_score(y_test, predictions_test4)\n","test_accuracy5 = accuracy_score(y_test, predictions_test5)\n","test_accuracy = (test_accuracy1 + valid_accuracy2 + valid_accuracy3 + valid_accuracy4 + valid_accuracy5)/5\n","print(f\"Avg Test Accuracy: {test_accuracy}\")"]},{"cell_type":"code","source":["pooled_predictions = []\n","for i in range(len(predictions_test1)):\n","  predicted_true = 0\n","  predicted_false = 0\n","  for prediction_list in [predictions_test1, predictions_test2, predictions_test3, predictions_test4, predictions_test5]:\n","    if prediction_list[i] == 'T':\n","       predicted_true += 1\n","    else:\n","      predicted_false += 1\n","  if predicted_true > predicted_false:\n","    pooled_predictions.append('T')\n","  else:\n","    pooled_predictions.append('F')\n","\n","pooled_test_accuracy = accuracy_score(y_test, pooled_predictions)\n","print(f\"Test Accuracy With Pooling: {pooled_test_accuracy}\")\n","\n","print(\"Criterion:\", best_criterion)\n","print(\"Min Samples To Split:\", best_min_samples_split)\n","print(\"Max Features:\", best_max_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V_-W7ucF1IhW","executionInfo":{"status":"ok","timestamp":1701055862640,"user_tz":360,"elapsed":6,"user":{"displayName":"Alexander Romanenko","userId":"05913195296226834875"}},"outputId":"162f7dc1-adf8-4c24-9226-e463c234821d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy With Pooling: 0.5721925133689839\n","Criterion: gini\n","Min Samples To Split: 77\n","Max Features: 50\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1701044551213,"user":{"displayName":"Alexander Romanenko","userId":"05913195296226834875"},"user_tz":360},"id":"NK2ko8KxJUaZ","outputId":"73759d7e-c613-4412-a10b-2722fdc8f82b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.48128342245989303\n"]}],"source":["random_list = [random.choice([\"T\", \"F\"]) for _ in range(len(y_test))]\n","test_accuracy = accuracy_score(y_test, random_list)\n","print(f\"Accuracy: {test_accuracy}\")"]},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","import numpy as np\n","import copy\n","\n","# Read the CSV file into a DataFrame\n","data = pd.read_csv('sample_data/Final_Data_NFL.csv')\n","\n","# Creating a new DataFrame with all columns except 'column2' and 'column4'\n","columns_to_exclude = ['Day', 'Date', 'Time', 'Favorite', 'FavoriteTeamYear', 'UnderdogTeamYear',\n","                      'Score', 'Underdog', 'OverUnder', 'Season_Year', 'Favorite_Covered']\n","X = data.drop(columns=columns_to_exclude)\n","Y = data[\"Favorite_Covered\"]\n","\n","# Convert time of posession columns to numbers\n","for col_name in ['Favoriteaverage-time-of-possession-net-of-ot', 'Favoriteopponent-average-time-of-possession-net-of-ot', 'Underdogaverage-time-of-possession-net-of-ot', 'Underdogopponent-average-time-of-possession-net-of-ot']:\n","  col_data = X[col_name]\n","  new_col_data = []\n","  for row in col_data:\n","    split_data = row.split(':')\n","    col_data = 60*int(split_data[0]) + int(split_data[1])\n","    new_col_data.append(col_data)\n","  X[col_name] = new_col_data\n","\n","# Convert % to float\n","for col_name in [\n","    \"Favoritered-zone-scoring-pct\", \"Favoritethird-down-conversion-pct\", \"Favoritefield-goal-conversion-pct\",\n","    \"Favoriteopponent-red-zone-scoring-pct\", \"Favoriteopponent-third-down-conversion-pct\", \"Favoriteopponent-completion-pct\",\n","    \"Favoriteopponent-field-goal-conversion-pct\", \"Underdogred-zone-scoring-pct\", \"Underdogthird-down-conversion-pct\",\n","    \"Underdogfield-goal-conversion-pct\", \"Underdogopponent-red-zone-scoring-pct\", \"Underdogopponent-third-down-conversion-pct\",\n","    \"Underdogopponent-completion-pct\", \"Underdogopponent-field-goal-conversion-pct\"\n","]:\n","  col_data = X[col_name]\n","  new_col_data = []\n","  for row in col_data:\n","    col_data = row[0:-1]\n","    new_col_data.append(col_data)\n","  X[col_name] = new_col_data\n","\n","# If there is not a reported spread, get rid of the row of data\n","indices = []\n","for i, row in enumerate(X['Spread']):\n","  if str(row) == 'nan':\n","    indices.append(i)\n","X = X.drop(indices)\n","Y = Y.drop(indices)\n","\n","\n","# If there is a push and both sides of bet get their money back -set the label to P\n","new_Y = []\n","for row in Y:\n","  if row == 'T' or row == 'F':\n","    val = row\n","  else:\n","    val = 'T'\n","  new_Y.append(val)\n","Y = pd.Series(new_Y)\n","\n","# Splitting the data into training and testing sets(70%, 15%, 15%) - 5 times\n","# We will choose the most classified label provided by the 5 random forests when making predictions\n","X_temp1, X_test, y_temp1, y_test= train_test_split(X, Y, test_size=0.15, random_state=1)\n","X_train1, X_valid1, y_train1, y_valid1 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=1)\n","X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=2)\n","X_train3, X_valid3, y_train3, y_valid3 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=3)\n","X_train4, X_valid4, y_train4, y_valid4 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=4)\n","X_train5, X_valid5, y_train5, y_valid5 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=5)\n","X_train6, X_valid6, y_train6, y_valid6 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=6)\n","X_train7, X_valid7, y_train7, y_valid7 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=7)\n","X_train8, X_valid8, y_train8, y_valid8 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=8)\n","X_train9, X_valid9, y_train9, y_valid9 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=9)\n","X_train10, X_valid10, y_train10, y_valid10 = train_test_split(X_temp1, y_temp1, test_size=0.176, random_state=10)\n","\n","best_valid_accuracy = 0\n","best_classifier1 = None\n","best_classifier2 = None\n","best_classifier3 = None\n","best_classifier4 = None\n","best_classifier5 = None\n","best_classifier6 = None\n","best_classifier7 = None\n","best_classifier8 = None\n","best_classifier9 = None\n","best_classifier10 = None\n","best_criterion = None\n","best_min_samples_split = None\n","best_max_features = None\n","# Creating a Random Forest classifier - based on 100 decision trees\n","criterion_iter = -1\n","for criterion in [\"gini\", \"entropy\"]:\n","  criterion_iter += 1\n","  for min_samples_split in range(2, 200, 5):\n","    print(\"Progress =\", round(min_samples_split/400 * 100 + (criterion_iter*50),2), \"%\")\n","    for max_features in [10, 20, 30, 40, 50, \"sqrt\"]:\n","      rf_classifier1 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=1)\n","      rf_classifier2 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=2)\n","      rf_classifier3 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=3)\n","      rf_classifier4 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=4)\n","      rf_classifier5 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=5)\n","      rf_classifier6 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=6)\n","      rf_classifier7 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=7)\n","      rf_classifier8 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=8)\n","      rf_classifier9 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=9)\n","      rf_classifier10 = RandomForestClassifier(n_estimators=20, criterion = criterion, min_samples_split = min_samples_split, max_features = max_features, random_state=10)\n","\n","      # Training the classifier\n","      rf_classifier1.fit(X_train1, y_train1)\n","      rf_classifier2.fit(X_train2, y_train2)\n","      rf_classifier3.fit(X_train3, y_train3)\n","      rf_classifier4.fit(X_train4, y_train4)\n","      rf_classifier5.fit(X_train5, y_train5)\n","      rf_classifier6.fit(X_train6, y_train6)\n","      rf_classifier7.fit(X_train7, y_train7)\n","      rf_classifier8.fit(X_train8, y_train8)\n","      rf_classifier9.fit(X_train9, y_train9)\n","      rf_classifier10.fit(X_train10, y_train10)\n","\n","      # Predicting on the valid set\n","      predictions_valid1 = rf_classifier1.predict(X_valid1)\n","      predictions_valid2 = rf_classifier2.predict(X_valid2)\n","      predictions_valid3 = rf_classifier3.predict(X_valid3)\n","      predictions_valid4 = rf_classifier4.predict(X_valid4)\n","      predictions_valid5 = rf_classifier5.predict(X_valid5)\n","      predictions_valid6 = rf_classifier5.predict(X_valid6)\n","      predictions_valid7 = rf_classifier5.predict(X_valid7)\n","      predictions_valid8 = rf_classifier5.predict(X_valid8)\n","      predictions_valid9 = rf_classifier5.predict(X_valid9)\n","      predictions_valid10 = rf_classifier5.predict(X_valid10)\n","\n","      # Calculating accuracy - valid\n","      valid_accuracy1 = accuracy_score(y_valid1, predictions_valid1)\n","      valid_accuracy2 = accuracy_score(y_valid2, predictions_valid2)\n","      valid_accuracy3 = accuracy_score(y_valid3, predictions_valid3)\n","      valid_accuracy4 = accuracy_score(y_valid4, predictions_valid4)\n","      valid_accuracy5 = accuracy_score(y_valid5, predictions_valid5)\n","      valid_accuracy6 = accuracy_score(y_valid6, predictions_valid6)\n","      valid_accuracy7 = accuracy_score(y_valid7, predictions_valid7)\n","      valid_accuracy8 = accuracy_score(y_valid8, predictions_valid8)\n","      valid_accuracy9 = accuracy_score(y_valid9, predictions_valid9)\n","      valid_accuracy10 = accuracy_score(y_valid10, predictions_valid10)\n","      valid_accuracy = (valid_accuracy1 + valid_accuracy2 + valid_accuracy3 + valid_accuracy4 + valid_accuracy5 + valid_accuracy6 + valid_accuracy7 + valid_accuracy8 + valid_accuracy9 + valid_accuracy10)/10\n","\n","      if valid_accuracy > best_valid_accuracy:\n","        best_valid_accuracy = valid_accuracy\n","        best_classifier1 = copy.deepcopy(rf_classifier1)\n","        best_classifier2 = copy.deepcopy(rf_classifier2)\n","        best_classifier3 = copy.deepcopy(rf_classifier3)\n","        best_classifier4 = copy.deepcopy(rf_classifier4)\n","        best_classifier5 = copy.deepcopy(rf_classifier5)\n","        best_classifier6 = copy.deepcopy(rf_classifier6)\n","        best_classifier7 = copy.deepcopy(rf_classifier7)\n","        best_classifier8 = copy.deepcopy(rf_classifier8)\n","        best_classifier9 = copy.deepcopy(rf_classifier9)\n","        best_classifier10 = copy.deepcopy(rf_classifier10)\n","\n","        best_criterion = criterion\n","        best_min_samples_split = min_samples_split\n","        best_max_features = max_features\n","\n","# Predicting on the train set\n","predictions_train1 = rf_classifier1.predict(X_train1)\n","predictions_train2 = rf_classifier2.predict(X_train2)\n","predictions_train3 = rf_classifier3.predict(X_train3)\n","predictions_train4 = rf_classifier4.predict(X_train4)\n","predictions_train5 = rf_classifier5.predict(X_train5)\n","predictions_train6 = rf_classifier6.predict(X_train6)\n","predictions_train7 = rf_classifier7.predict(X_train7)\n","predictions_train8 = rf_classifier8.predict(X_train8)\n","predictions_train9 = rf_classifier9.predict(X_train9)\n","predictions_train10 = rf_classifier10.predict(X_train10)\n","\n","train_accuracy1 = accuracy_score(y_train1, predictions_train1)\n","train_accuracy2 = accuracy_score(y_train2, predictions_train2)\n","train_accuracy3 = accuracy_score(y_train3, predictions_train3)\n","train_accuracy4 = accuracy_score(y_train4, predictions_train4)\n","train_accuracy5 = accuracy_score(y_train5, predictions_train5)\n","train_accuracy6 = accuracy_score(y_train6, predictions_train6)\n","train_accuracy7 = accuracy_score(y_train7, predictions_train7)\n","train_accuracy8 = accuracy_score(y_train8, predictions_train8)\n","train_accuracy9 = accuracy_score(y_train9, predictions_train9)\n","train_accuracy10 = accuracy_score(y_train10, predictions_train10)\n","train_accuracy = (train_accuracy1 + train_accuracy2 + train_accuracy3 + train_accuracy4 + train_accuracy5 + train_accuracy6 + train_accuracy7 + train_accuracy8 + train_accuracy9 + train_accuracy10)/10\n","print(f\"Avg Train Accuracy: {train_accuracy}\")\n","\n","# Predicting on the valid set\n","predictions_valid1 = rf_classifier1.predict(X_valid1)\n","predictions_valid2 = rf_classifier2.predict(X_valid2)\n","predictions_valid3 = rf_classifier3.predict(X_valid3)\n","predictions_valid4 = rf_classifier4.predict(X_valid4)\n","predictions_valid5 = rf_classifier5.predict(X_valid5)\n","predictions_valid6 = rf_classifier5.predict(X_valid6)\n","predictions_valid7 = rf_classifier5.predict(X_valid7)\n","predictions_valid8 = rf_classifier5.predict(X_valid8)\n","predictions_valid9 = rf_classifier5.predict(X_valid9)\n","predictions_valid10 = rf_classifier5.predict(X_valid10)\n","\n","valid_accuracy1 = accuracy_score(y_valid1, predictions_valid1)\n","valid_accuracy2 = accuracy_score(y_valid2, predictions_valid2)\n","valid_accuracy3 = accuracy_score(y_valid3, predictions_valid3)\n","valid_accuracy4 = accuracy_score(y_valid4, predictions_valid4)\n","valid_accuracy5 = accuracy_score(y_valid5, predictions_valid5)\n","valid_accuracy6 = accuracy_score(y_valid6, predictions_valid6)\n","valid_accuracy7 = accuracy_score(y_valid7, predictions_valid7)\n","valid_accuracy8 = accuracy_score(y_valid8, predictions_valid8)\n","valid_accuracy9 = accuracy_score(y_valid9, predictions_valid9)\n","valid_accuracy10 = accuracy_score(y_valid10, predictions_valid10)\n","valid_accuracy = (valid_accuracy1 + valid_accuracy2 + valid_accuracy3 + valid_accuracy4 + valid_accuracy5 + valid_accuracy6 + valid_accuracy7 + valid_accuracy8 + valid_accuracy9 + valid_accuracy10)/10\n","print(f\"Avg Valid Accuracy: {valid_accuracy}\")\n","\n","# Predicting on the test set\n","predictions_test1 = rf_classifier1.predict(X_test)\n","predictions_test2 = rf_classifier2.predict(X_test)\n","predictions_test3 = rf_classifier3.predict(X_test)\n","predictions_test4 = rf_classifier4.predict(X_test)\n","predictions_test5 = rf_classifier5.predict(X_test)\n","predictions_test6 = rf_classifier6.predict(X_test)\n","predictions_test7 = rf_classifier7.predict(X_test)\n","predictions_test8 = rf_classifier8.predict(X_test)\n","predictions_test9 = rf_classifier9.predict(X_test)\n","predictions_test10 = rf_classifier10.predict(X_test)\n","\n","test_accuracy1 = accuracy_score(y_test, predictions_test1)\n","test_accuracy2 = accuracy_score(y_test, predictions_test2)\n","test_accuracy3 = accuracy_score(y_test, predictions_test3)\n","test_accuracy4 = accuracy_score(y_test, predictions_test4)\n","test_accuracy5 = accuracy_score(y_test, predictions_test5)\n","test_accuracy6 = accuracy_score(y_test, predictions_test6)\n","test_accuracy7 = accuracy_score(y_test, predictions_test7)\n","test_accuracy8 = accuracy_score(y_test, predictions_test8)\n","test_accuracy9 = accuracy_score(y_test, predictions_test9)\n","test_accuracy10 = accuracy_score(y_test, predictions_test10)\n","test_accuracy = (test_accuracy1 + test_accuracy2 + test_accuracy3 + test_accuracy4 + test_accuracy5 + test_accuracy6 + test_accuracy7 + test_accuracy8 + test_accuracy9 + test_accuracy10)/10\n","print(f\"Avg Test Accuracy: {test_accuracy}\")\n","\n","pooled_predictions = []\n","for i in range(len(predictions_test1)):\n","  predicted_true = 0\n","  predicted_false = 0\n","  for prediction_list in [predictions_test1, predictions_test2, predictions_test3, predictions_test4, predictions_test5, predictions_test6, predictions_test7, predictions_test8, predictions_test9, predictions_test10]:\n","    if prediction_list[i] == 'T':\n","       predicted_true += 1\n","    else:\n","      predicted_false += 1\n","  if predicted_true > predicted_false:\n","    pooled_predictions.append('T')\n","  else:\n","    pooled_predictions.append('F')\n","\n","pooled_test_accuracy = accuracy_score(y_test, pooled_predictions)\n","print(f\"Test Accuracy With Pooling: {pooled_test_accuracy}\")\n","\n","print(\"Criterion:\", best_criterion)\n","print(\"Min Samples To Split:\", best_min_samples_split)\n","print(\"Max Features:\", best_max_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_xpI_8wV7QEB","outputId":"cd654023-a0a0-4357-c437-b6c903a83eec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Progress = 0.5 %\n","Progress = 1.75 %\n","Progress = 3.0 %\n","Progress = 4.25 %\n","Progress = 5.5 %\n","Progress = 6.75 %\n","Progress = 8.0 %\n","Progress = 9.25 %\n","Progress = 10.5 %\n","Progress = 11.75 %\n","Progress = 13.0 %\n","Progress = 14.25 %\n","Progress = 15.5 %\n","Progress = 16.75 %\n","Progress = 18.0 %\n","Progress = 19.25 %\n","Progress = 20.5 %\n","Progress = 21.75 %\n","Progress = 23.0 %\n","Progress = 24.25 %\n","Progress = 25.5 %\n","Progress = 26.75 %\n","Progress = 28.0 %\n","Progress = 29.25 %\n","Progress = 30.5 %\n","Progress = 31.75 %\n","Progress = 33.0 %\n","Progress = 34.25 %\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmIiYZfJn/AmFHHfzNIiMZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
>>>>>>> b4c9bf45821313ee335d02a74f8d2130dfe65f15
